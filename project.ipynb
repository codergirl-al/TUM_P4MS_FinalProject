{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EPL Match Data Analysis (2000-2025)\n",
    "\n",
    "**Dataset:** English Premier League Match Data 2000–2025  \n",
    "**Objective:** Analyze trends in match results and explore factors influencing match outcomes.\n",
    "\n",
    "## Research Questions\n",
    "1. Home Advantage Analysis:\n",
    "\"Has home advantage in the Premier League changed over the 25-year period, and what factors contribute most to this phenomenon?\"\n",
    "\n",
    "This question addresses one of football's most studied phenomena and allows for temporal trend analysis using statistical testing methods.\n",
    "\n",
    "2. Match Outcome Prediction:\n",
    "\"Can we accurately predict match results using in-game statistics, and which variables are most predictive of success?\"\n",
    "\n",
    "This enables application of machine learning techniques while demonstrating feature importance analysis and model validation.\n",
    "\n",
    "3. Team Performance Evolution:\n",
    "\"How has competitive balance evolved in the Premier League, and which teams demonstrate the most consistent performance patterns?\"\n",
    "\n",
    "This question facilitates comparative analysis across teams and seasons using various statistical measures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning & Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d423eda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports & Settings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "855d368d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading & Initial Inspection\n",
    "\n",
    "def load_and_inspect_data(file_path):\n",
    "    \"\"\"\n",
    "    Load EPL dataset from CSV and display basic info.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path, parse_dates=['MatchDate'], dayfirst=True)\n",
    "    \n",
    "    print(\"=== INITIAL DATA INSPECTION ===\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(df.dtypes)\n",
    "    print(df.head(3))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83f6d12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Cleaning Function\n",
    "\n",
    "def initial_clean_data(df):\n",
    "    \"\"\"\n",
    "    - Parse dates, drop invalid/missing core rows\n",
    "    - Convert goals to numeric, strip whitespace, drop duplicates\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    # 1. Date parsing\n",
    "    if 'MatchDate' in df.columns:\n",
    "        df['MatchDate'] = pd.to_datetime(df['MatchDate'], errors='coerce')\n",
    "    # 2. Drop rows missing essentials\n",
    "    df.dropna(subset=['MatchDate', 'HomeTeam', 'AwayTeam', \n",
    "                      'FullTimeHomeGoals', 'FullTimeAwayGoals'], inplace=True)\n",
    "    # 3. Numeric conversion\n",
    "    for col in ['FullTimeHomeGoals','FullTimeAwayGoals',\n",
    "                'HalfTimeHomeGoals','HalfTimeAwayGoals']:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    # 4. Strip whitespace\n",
    "    for col in df.select_dtypes(include=['object']):\n",
    "        df[col] = df[col].str.strip()\n",
    "    # 5. Drop duplicates\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Data Quality Assessment\n",
    "\n",
    "def comprehensive_data_quality_assessment(df):\n",
    "    \"\"\"\n",
    "    - Missing values summary\n",
    "    - Data types & uniqueness\n",
    "    - Logical consistency checks\n",
    "    \"\"\"\n",
    "    print(\"=== DATA QUALITY ASSESSMENT ===\")\n",
    "    # Missing\n",
    "    miss = df.isnull().sum()\n",
    "    pct = 100 * miss / len(df)\n",
    "    miss_df = pd.DataFrame({'count': miss, 'pct': pct}).sort_values('pct', ascending=False)\n",
    "    print(\"\\nMissing values:\")\n",
    "    print(miss_df[miss_df['count'] > 0])\n",
    "    # Dtypes & unique\n",
    "    dtype_df = pd.DataFrame({\n",
    "        'dtype': df.dtypes,\n",
    "        'non_null': df.count(),\n",
    "        'n_unique': [df[c].nunique() for c in df.columns]\n",
    "    })\n",
    "    print(\"\\nData types & unique counts:\")\n",
    "    print(dtype_df)\n",
    "    # Check teams not playing themselves\n",
    "    same = df[df['HomeTeam']==df['AwayTeam']]\n",
    "    print(f\"\\nTeams vs themselves: {len(same)} rows\")\n",
    "    # Shots on target not > shots\n",
    "    if 'HomeShotsOnTarget' in df and 'HomeShots' in df:\n",
    "        bad_shots = df[(df['HomeShotsOnTarget']>df['HomeShots']) |\n",
    "                       (df['AwayShotsOnTarget']>df['AwayShots'])]\n",
    "        print(f\"Shot-target inconsistencies: {len(bad_shots)} rows\")\n",
    "    return {\n",
    "        'missing_summary': miss_df,\n",
    "        'dtype_summary': dtype_df,\n",
    "        'same_team_issues': len(same),\n",
    "        'shot_issues': len(bad_shots) if 'bad_shots' in locals() else 0\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4cad978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier Detection & Treatment\n",
    "\n",
    "def detect_and_handle_outliers(df, method='iqr'):\n",
    "    \"\"\"\n",
    "    - IQR-based capping for numeric cols\n",
    "    - Sport-specific flags for extremes\n",
    "    \"\"\"\n",
    "    print(\"=== OUTLIER DETECTION & TREATMENT ===\")\n",
    "    df_out = df.copy()\n",
    "    num_cols = df_out.select_dtypes(include=[np.number]).columns\n",
    "    for col in num_cols:\n",
    "        Q1, Q3 = df_out[col].quantile([0.25,0.75])\n",
    "        IQR = Q3 - Q1\n",
    "        lb, ub = Q1 - 1.5*IQR, Q3 + 1.5*IQR\n",
    "        df_out[col] = df_out[col].clip(lb, ub)\n",
    "        print(f\"{col}: capped at [{lb:.2f}, {ub:.2f}]\")\n",
    "    # Flags\n",
    "    if 'TotalGoals' in df_out:\n",
    "        df_out['HighScoringGame'] = df_out['TotalGoals'] > 5\n",
    "    if 'HomeYellowCards' in df_out and 'AwayYellowCards' in df_out:\n",
    "        df_out['VeryPhysicalGame'] = (df_out['HomeYellowCards']+df_out['AwayYellowCards']) >= 8\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e14e15c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing Value Treatment\n",
    "\n",
    "def advanced_missing_value_treatment(df):\n",
    "    \"\"\"\n",
    "    - Impute numeric with median or team-based median for corners\n",
    "    \"\"\"\n",
    "    print(\"=== MISSING VALUE TREATMENT ===\")\n",
    "    df_imp = df.copy()\n",
    "    for col in df_imp.columns[df_imp.isnull().any()]:\n",
    "        if 'Corner' in col and 'Team' in col:\n",
    "            # team-based median\n",
    "            team_col = 'HomeTeam' if 'HomeCorners' in col else 'AwayTeam'\n",
    "            med = df_imp.groupby(team_col)[col].transform('median')\n",
    "            df_imp[col] = df_imp[col].fillna(med)\n",
    "            print(f\"{col}: team-based median\")\n",
    "        elif df_imp[col].dtype in [np.float64, np.int64]:\n",
    "            med = df_imp[col].median()\n",
    "            df_imp[col].fillna(med, inplace=True)\n",
    "            print(f\"{col}: global median {med:.2f}\")\n",
    "        else:\n",
    "            df_imp[col].fillna('', inplace=True)\n",
    "            print(f\"{col}: filled empty string\")\n",
    "    return df_imp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78b91a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "\n",
    "def comprehensive_feature_engineering(df):\n",
    "    \"\"\"\n",
    "    - Temporal, result, performance, competitiveness, expected goals\n",
    "    \"\"\"\n",
    "    print(\"=== FEATURE ENGINEERING ===\")\n",
    "    df_fe = df.copy()\n",
    "    # Temporal\n",
    "    df_fe['Year']   = df_fe['MatchDate'].dt.year\n",
    "    df_fe['Month']  = df_fe['MatchDate'].dt.month\n",
    "    df_fe['Weekday']= df_fe['MatchDate'].dt.day_name()\n",
    "    df_fe['Season'] = df_fe['MatchDate'].apply(\n",
    "        lambda x: f\"{x.year}/{x.year+1}\" if x.month>=8 else f\"{x.year-1}/{x.year}\"\n",
    "    )\n",
    "    # Totals & diffs\n",
    "    df_fe['TotalGoals']      = df_fe['FullTimeHomeGoals'] + df_fe['FullTimeAwayGoals']\n",
    "    df_fe['GoalDifference']  = df_fe['FullTimeHomeGoals'] - df_fe['FullTimeAwayGoals']\n",
    "    # Result\n",
    "    df_fe['Result'] = df_fe.apply(\n",
    "        lambda r: 'H' if r.FullTimeHomeGoals>r.FullTimeAwayGoals \n",
    "                  else ('A' if r.FullTimeAwayGoals>r.FullTimeHomeGoals else 'D'), axis=1\n",
    "    )\n",
    "    # Accuracy & conversion\n",
    "    df_fe['HomeShotAccuracy'] = (df_fe['HomeShotsOnTarget']/df_fe['HomeShots']).fillna(0)\n",
    "    df_fe['AwayShotAccuracy'] = (df_fe['AwayShotsOnTarget']/df_fe['AwayShots']).fillna(0)\n",
    "    df_fe['HomeConversionRate']= (df_fe['FullTimeHomeGoals']/df_fe['HomeShotsOnTarget']).fillna(0)\n",
    "    df_fe['AwayConversionRate']= (df_fe['FullTimeAwayGoals']/df_fe['AwayShotsOnTarget']).fillna(0)\n",
    "    # Competitiveness & excitement\n",
    "    df_fe['MatchCompetitiveness'] = 1/(1+df_fe['GoalDifference'].abs())\n",
    "    df_fe['ExcitementIndex']      = df_fe['TotalGoals']*2 + df_fe.get('HomeCorners',0)+df_fe.get('AwayCorners',0)\n",
    "    # Expected Goals approx\n",
    "    df_fe['HomeExpectedGoals'] = df_fe['HomeShotsOnTarget']*0.3 + df_fe.get('HomeCorners',0)*0.1\n",
    "    df_fe['AwayExpectedGoals'] = df_fe['AwayShotsOnTarget']*0.3 + df_fe.get('AwayCorners',0)*0.1\n",
    "    return df_fe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "409fd393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Validation\n",
    "\n",
    "def comprehensive_data_validation(df_orig, df_proc):\n",
    "    \"\"\"\n",
    "    - Row count, missing fill, logic checks, overall score\n",
    "    \"\"\"\n",
    "    print(\"=== PIPELINE VALIDATION ===\")\n",
    "    # Rows\n",
    "    if len(df_orig)==len(df_proc):\n",
    "        print(f\"Rows preserved: {len(df_proc)}\")\n",
    "    else:\n",
    "        print(f\"Rows changed: {len(df_orig)} → {len(df_proc)}\")\n",
    "    # Missing\n",
    "    print(f\"Missing values: {df_orig.isnull().sum().sum()} → {df_proc.isnull().sum().sum()}\")\n",
    "    # Logic\n",
    "    bad = df_proc[df_proc['TotalGoals'] != \n",
    "                 (df_proc['FullTimeHomeGoals']+df_proc['FullTimeAwayGoals'])]\n",
    "    print(f\"Inconsistent goal sums: {len(bad)} rows\")\n",
    "    # Score\n",
    "    score = 0\n",
    "    score += 25 if len(df_orig)==len(df_proc) else 0\n",
    "    score += 25 if df_proc.isnull().sum().sum() < df_orig.isnull().sum().sum() else 0\n",
    "    score += 25 if len(bad)==0 else 0\n",
    "    score += 25 if (df_proc.shape[1]-df_orig.shape[1]) > df_orig.shape[1]*0.5 else 0\n",
    "    print(f\"Quality score: {score}/100\")\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0e0bc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# End-to-End Pipeline\n",
    "\n",
    "def complete_epl_data_preparation_pipeline(\n",
    "    file_path=None, export_path=None, sample_data=False\n",
    "):\n",
    "    # 1. Load\n",
    "    df = load_and_inspect_data(file_path, sample_data=sample_data)\n",
    "    # 2. Initial clean\n",
    "    df = initial_clean_data(df)\n",
    "    # 3. Quality assessment\n",
    "    qa = comprehensive_data_quality_assessment(df)\n",
    "    # 4. Outlier handling\n",
    "    df = detect_and_handle_outliers(df)\n",
    "    # 5. Missing value treatment\n",
    "    df = advanced_missing_value_treatment(df)\n",
    "    # 6. Feature engineering\n",
    "    df = comprehensive_feature_engineering(df)\n",
    "    # 7. Validation\n",
    "    score = comprehensive_data_validation(\n",
    "        initial_clean_data(load_and_inspect_data(file_path, sample_data=sample_data)), \n",
    "        df\n",
    "    )\n",
    "    # 8. Export\n",
    "    if export_path:\n",
    "        df.to_csv(export_path, index=False)\n",
    "        print(f\"Exported to {export_path}\")\n",
    "    return df, qa, score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2fa13720",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "load_and_inspect_data() got an unexpected keyword argument 'sample_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Run Pipeline\u001b[39;00m\n\u001b[1;32m      3\u001b[0m data_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m cleaned_df, quality_report, quality_score \u001b[38;5;241m=\u001b[39m \u001b[43mcomplete_epl_data_preparation_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepl_cleaned_full_pipeline.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[29], line 7\u001b[0m, in \u001b[0;36mcomplete_epl_data_preparation_pipeline\u001b[0;34m(file_path, export_path, sample_data)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcomplete_epl_data_preparation_pipeline\u001b[39m(\n\u001b[1;32m      4\u001b[0m     file_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, export_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      5\u001b[0m ):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# 1. Load\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mload_and_inspect_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# 2. Initial clean\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     df \u001b[38;5;241m=\u001b[39m initial_clean_data(df)\n",
      "\u001b[0;31mTypeError\u001b[0m: load_and_inspect_data() got an unexpected keyword argument 'sample_data'"
     ]
    }
   ],
   "source": [
    "# Run Pipeline\n",
    "\n",
    "data_path = \"dataset.csv\"\n",
    "cleaned_df, quality_report, quality_score = complete_epl_data_preparation_pipeline(\n",
    "    file_path=data_path,\n",
    "    export_path=\"epl_cleaned_full_pipeline.csv\",\n",
    "    sample_data=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b491754d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick Visualizations\n",
    "\n",
    "# Goals per season\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(x='Season', y='TotalGoals', data=cleaned_df)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Goals per Season\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Matches per weekday\n",
    "plt.figure(figsize=(8,5))\n",
    "order = ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']\n",
    "sns.countplot(x='Weekday', data=cleaned_df, order=order)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Match Distribution by Weekday\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817eea74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Goals per Season Trend\n",
    "\n",
    "if 'Season' in cleaned_df.columns and \\\n",
    "   'FullTimeHomeGoals' in cleaned_df.columns and \\\n",
    "   'FullTimeAwayGoals' in cleaned_df.columns:\n",
    "\n",
    "    goals_per_season = (\n",
    "        cleaned_df\n",
    "        .groupby('Season')[['FullTimeHomeGoals','FullTimeAwayGoals']]\n",
    "        .sum()\n",
    "    )\n",
    "    goals_per_season['TotalGoals'] = (\n",
    "        goals_per_season['FullTimeHomeGoals'] +\n",
    "        goals_per_season['FullTimeAwayGoals']\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.lineplot(\n",
    "        x=goals_per_season.index,\n",
    "        y='TotalGoals',\n",
    "        data=goals_per_season,\n",
    "        marker='o'\n",
    "    )\n",
    "    plt.title('Total Goals per Season')\n",
    "    plt.xlabel('Season')\n",
    "    plt.ylabel('Total Goals')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Column 'Season' or goal columns not found in cleaned_df.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4699e725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match Outcomes Distribution\n",
    "\n",
    "if 'Result' in cleaned_df.columns:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.countplot(\n",
    "        x='Result',\n",
    "        data=cleaned_df,\n",
    "        palette='Set2'\n",
    "    )\n",
    "    plt.title('Match Outcomes Distribution (H=Home win, D=Draw, A=Away win)')\n",
    "    plt.xlabel('Result')\n",
    "    plt.ylabel('Count')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Column 'Result' not found in cleaned_df.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40288312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Summary Statistics\n",
    "\n",
    "def custom_summary(df):\n",
    "    \"\"\"\n",
    "    Compute summary statistics for each numeric column:\n",
    "      count, mean, median, std, min, 25%, 50%, 75%, max\n",
    "    \"\"\"\n",
    "    num = df.select_dtypes(include=[np.number])\n",
    "    stats = {}\n",
    "    for col in num.columns:\n",
    "        s = num[col].dropna()\n",
    "        stats[col] = {\n",
    "            'count':    s.count(),\n",
    "            'mean':     s.mean(),\n",
    "            'median':   s.median(),\n",
    "            'std':      s.std(),\n",
    "            'min':      s.min(),\n",
    "            '25%':      s.quantile(0.25),\n",
    "            '50%':      s.quantile(0.50),\n",
    "            '75%':      s.quantile(0.75),\n",
    "            'max':      s.max()\n",
    "        }\n",
    "    summary_df = pd.DataFrame(stats).T\n",
    "    # Optional: round for readability\n",
    "    summary_df = summary_df.round(3)\n",
    "    print(\"=== Custom Summary Statistics ===\")\n",
    "    print(summary_df)\n",
    "    return summary_df\n",
    "\n",
    "# Usage:\n",
    "summary_stats = custom_summary(cleaned_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Match Outcome (Simple Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(dataframe):\n",
    "    \"\"\"\n",
    "    Builds a logistic regression model predicting match result.\n",
    "    \"\"\"\n",
    "    df_model = dataframe.copy()\n",
    "    \n",
    "    if 'FTR' not in df_model.columns:\n",
    "        print(\"FTR column not found.\")\n",
    "        return\n",
    "    \n",
    "    df_model = df_model.dropna(subset=['FTR'])\n",
    "    X = df_model[['FTHG','FTAG']]  # Features: goals scored\n",
    "    y = df_model['FTR']\n",
    "    \n",
    "    y_encoded = y.map({'H':0,'D':1,'A':2})\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y_encoded, test_size=0.2, random_state=RANDOM_STATE\n",
    "    )\n",
    "    \n",
    "    model = LogisticRegression(multi_class='multinomial', max_iter=500)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    cm = confusion_matrix(y_test, preds)\n",
    "    \n",
    "    print(f\"Accuracy: {acc:.2f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    return model\n",
    "\n",
    "_ = build_model(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "- Home wins remain frequent across seasons.\n",
    "- Goal totals fluctuate moderately.\n",
    "- Simple models can predict match outcome with modest accuracy.\n",
    "\n",
    "**Next steps:**\n",
    "- Incorporate more advanced features (team strength, odds).\n",
    "- Explore time-series forecasting.\n",
    "- Deploy interactive dashboards."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
